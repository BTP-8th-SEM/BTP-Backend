{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba747eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "390fa438",
   "metadata": {},
   "source": [
    "### Connect to DB and map Tables into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36eb30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27db1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataframes:\n",
    "    user=test=questions=options=responses=olap_test=olap_question=pd.DataFrame()\n",
    "    def __init__(self):\n",
    "        cnx = mysql.connector.connect(user='root', password='my123sql',\n",
    "                              host='localhost', database='intest')\n",
    "        \n",
    "        query_user = \"SELECT * FROM users\"\n",
    "        self.user = pd.read_sql(query_user, cnx)\n",
    "        \n",
    "        query_test = \"SELECT * FROM test_db\"\n",
    "        self.test= pd.read_sql(query_test, cnx)\n",
    "        \n",
    "        query_questions = \"SELECT * FROM questions\"\n",
    "        self.questions= pd.read_sql(query_questions, cnx)\n",
    "        \n",
    "        query_options = \"SELECT * FROM mcq_options\"\n",
    "        self.options= pd.read_sql(query_options, cnx)\n",
    "        \n",
    "        query_responses = \"SELECT * FROM responses\"\n",
    "        self.responses= pd.read_sql(query_responses, cnx)\n",
    "        \n",
    "        query_olap_test = \"SELECT * FROM olap_test\"\n",
    "        self.olap_test= pd.read_sql(query_olap_test, cnx)\n",
    "        \n",
    "        query_olap_question = \"SELECT * FROM olap_question\"\n",
    "        self.olap_question= pd.read_sql(query_olap_question, cnx)\n",
    "        \n",
    "        cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa9398c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baa2beb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses=df.responses\n",
    "idxList=responses.query('testId==1 & userId==3')\n",
    "idxList.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fbeffb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'questionId': 1,\n",
       " 'userId': 2,\n",
       " 'testId': 1,\n",
       " 'body': 'New Delhi',\n",
       " 'obtainedMarks': 5}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.responses.loc[0].to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f906f62b",
   "metadata": {},
   "source": [
    "### Run OLAP processes for TESTwise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3edd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLAP_Test:\n",
    "    df:dataframes\n",
    "    results={'id': 0, 'testId':0, 'totalAppeared':0, 'maxMarks':0, 'highestMarks':0, 'lowestMarks':0,\n",
    "             'avgMarks':0, 'noOfPassed':0, 'noOfFailed':0, 'lastUpdated': ''}\n",
    "    testId=0\n",
    "    \n",
    "    def __init__(self, df: dataframes, testId: int) -> None:\n",
    "        self.df=df\n",
    "        self.testId=testId\n",
    "        self.results['testId']=testId\n",
    "        \n",
    "        \n",
    "    def calculate(self):\n",
    "        \n",
    "        responses=self.df.responses.query('testId==@self.testId')\n",
    "        test=self.df.test.query('id==@self.testId')\n",
    "        \n",
    "        def setTotalAppeared():\n",
    "            self.results['totalAppeared']=len(responses['userId'].unique())\n",
    "        \n",
    "        def setMaxMarks():\n",
    "            mm=test['maxMarks'].loc[0]\n",
    "            self.results['maxMarks']=mm\n",
    "        \n",
    "        def setHighestMarks():\n",
    "            max_score = responses.groupby('userId')['obtainedMarks'].sum().max()\n",
    "            self.results['highestMarks']=max_score\n",
    "            \n",
    "        def setLowestMarks():\n",
    "            min_score = responses.groupby('userId')['obtainedMarks'].sum().min()\n",
    "            self.results['lowestMarks']=min_score\n",
    "        \n",
    "        def setAvgMarks():\n",
    "            average_marks = responses.groupby('userId')['obtainedMarks'].sum().mean()\n",
    "            self.results['avgMarks']=average_marks\n",
    "        \n",
    "        def setNoOfPassedandFailed():\n",
    "            passMarks=test.passMarks.loc[0]\n",
    "            passed=(responses.groupby('userId')['obtainedMarks'].sum() >= passMarks).sum()\n",
    "            self.results['noOfPassed']=passed\n",
    "            self.results['noOfFailed']=self.results['totalAppeared']-passed\n",
    "        setTotalAppeared()\n",
    "        setMaxMarks()\n",
    "        setHighestMarks()\n",
    "        setLowestMarks()\n",
    "        setAvgMarks()\n",
    "        setNoOfPassedandFailed()\n",
    "        return self.results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d89d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'testId': 1, 'totalAppeared': 4, 'maxMarks': 15, 'highestMarks': 15, 'lowestMarks': 0, 'avgMarks': 7.5, 'noOfPassed': 2, 'noOfFailed': 2, 'lastUpdated': ''}\n"
     ]
    }
   ],
   "source": [
    "o=OLAP_Test(df=df,testId=1)\n",
    "result=o.calculate()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "461bfae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_encoder(object):\n",
    "    if isinstance(object, np.generic):\n",
    "        return object.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9a3efdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 0, \"testId\": 1, \"totalAppeared\": 4, \"maxMarks\": 15, \"highestMarks\": 15, \"lowestMarks\": 0, \"avgMarks\": 7.5, \"noOfPassed\": 2, \"noOfFailed\": 2, \"lastUpdated\": \"\"}'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(result, default=np_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9e4538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id=0\n",
    "testId=1\n",
    "searchTest=df.olap_test.query('testId==@testId')\n",
    "if len(searchTest)>0:\n",
    "    id=searchTest.index()+1\n",
    "else:\n",
    "    id=len(df.olap_test)+1\n",
    "id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec2128ca",
   "metadata": {},
   "source": [
    "## OLAP Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53c3fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzes one question by its ID\n",
    "class OLAP_questions:\n",
    "    df:dataframes\n",
    "    result={'id': 0, 'questionId':0, 'maxMarks':0, 'highestMarks':0, 'lowestMarks':0,\n",
    "             'avgMarks':0, 'topic': ''}\n",
    "    testId:int\n",
    "    \n",
    "    #maps dataframes created and locks the testId\n",
    "    def __init__(self, df:dataframes, testId: int):\n",
    "        self.df=df\n",
    "        self.testId=testId\n",
    "        \n",
    "    #calculates analysis for a particular question by questionId\n",
    "    def calculate(self,questionId:int):\n",
    "        responses=self.df.responses.query('questionId==@questionId')\n",
    "        question=self.df.questions.query('id==@questionId')\n",
    "        self.result['questionId']=questionId\n",
    "        self.result['topic']=question['topic'].iloc[0]\n",
    "        self.result['maxMarks']=question['maxMarks'].iloc[0]\n",
    "        self.result['highestMarks']=responses['obtainedMarks'].max()\n",
    "        self.result['lowestMarks']=responses['obtainedMarks'].min()\n",
    "        self.result['avgMarks']=responses['obtainedMarks'].mean()\n",
    "\n",
    "        return self.result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c976f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questionId</th>\n",
       "      <th>userId</th>\n",
       "      <th>testId</th>\n",
       "      <th>body</th>\n",
       "      <th>obtainedMarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Rahul Gandhi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Rahul Gandhi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  questionId  userId  testId           body  obtainedMarks\n",
       "1    2           2       2       1  Narendra Modi              5\n",
       "4    5           2       3       1   Rahul Gandhi              0\n",
       "7   14           2       4       1  Narendra Modi              5\n",
       "10  17           2       5       1   Rahul Gandhi              0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionId=2\n",
    "responses=df.responses.query('questionId==@questionId')\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79cd0108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>optionsId</th>\n",
       "      <th>testId</th>\n",
       "      <th>maxMarks</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "      <th>answerType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Who is the current Prime Minister of India?</td>\n",
       "      <td>Government</td>\n",
       "      <td>mcq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  optionsId  testId  maxMarks  \\\n",
       "1   2          2       1         5   \n",
       "\n",
       "                                          body       topic answerType  \n",
       "1  Who is the current Prime Minister of India?  Government        mcq  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Government'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionId=2\n",
    "question=df.questions.query('id==@questionId')\n",
    "topic=question['topic'].iloc[0]\n",
    "display(question)\n",
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67ae63f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'questionId': 1,\n",
       " 'maxMarks': 5,\n",
       " 'highestMarks': 5,\n",
       " 'lowestMarks': 0,\n",
       " 'avgMarks': 2.5,\n",
       " 'topic': 'Cities'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olapq=OLAP_questions(df,1)\n",
    "olapq.calculate(questionId=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "117b3943",
   "metadata": {},
   "source": [
    "## OLAP Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb737b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#analyzes test scores wrt topics\n",
    "\n",
    "\n",
    "\n",
    "class studentAnalysis:\n",
    "    testId:int\n",
    "    df:dataframes\n",
    "    def __init__(self,df:dataframes) -> None:\n",
    "        self.df=df\n",
    "        \n",
    "    def getTestData(self, testId:int, studentId: int):\n",
    "        olapTest=OLAP_Test(df=self.df,testId=testId)\n",
    "        results=olapTest.calculate()\n",
    "        responses=self.df.responses.query('testId==@testId & userId==@studentId')\n",
    "        results['studentId']=studentId\n",
    "        results['totalMarksObtained']=responses['obtainedMarks'].sum()\n",
    "        return results\n",
    "    \n",
    "    def getQuestionData(self, testId:int, studentId: int, questionId: int):\n",
    "        olapq=OLAP_questions(df=self.df,testId=testId)\n",
    "        result=olapq.calculate(questionId=questionId)\n",
    "        response=self.df.responses.query('testId==@testId & userId==@studentId & questionId==@questionId')\n",
    "        result['obtainedMarks']=response['obtainedMarks'].iloc[0]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38c0f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'testId': 1,\n",
       " 'totalAppeared': 4,\n",
       " 'maxMarks': 15,\n",
       " 'highestMarks': 15,\n",
       " 'lowestMarks': 0,\n",
       " 'avgMarks': 7.5,\n",
       " 'noOfPassed': 2,\n",
       " 'noOfFailed': 2,\n",
       " 'lastUpdated': '',\n",
       " 'studentId': 2,\n",
       " 'totalMarksObtained': 15}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dataframes()\n",
    "sa=studentAnalysis(df)\n",
    "sa.getTestData(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01e4b424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testId=1\n",
    "userId=2\n",
    "questionId=1\n",
    "response=df.responses.query('testId==@testId & userId==@userId & questionId==@questionId')\n",
    "response['obtainedMarks'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98a3c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'questionId': 1, 'maxMarks': 5, 'highestMarks': 5, 'lowestMarks': 0, 'avgMarks': 2.5, 'topic': 'Cities', 'obtainedMarks': 5}\n"
     ]
    }
   ],
   "source": [
    "q=sa.getQuestionData(testId=1,studentId=2,questionId=1)\n",
    "print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
