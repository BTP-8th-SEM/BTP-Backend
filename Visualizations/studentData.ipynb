{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a MySQL connection\n",
    "cnx = mysql.connector.connect(user='root', password='my123sql',\n",
    "                              host='localhost', database='intest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataframes:\n",
    "    user=test=questions=options=responses=olap_test=olap_question=pd.DataFrame()\n",
    "    def __init__(self):\n",
    "        cnx = mysql.connector.connect(user='root', password='my123sql',\n",
    "                              host='localhost', database='intest')\n",
    "        \n",
    "        query_user = \"SELECT * FROM users\"\n",
    "        self.user = pd.read_sql(query_user, cnx)\n",
    "        \n",
    "        query_test = \"SELECT * FROM test_db\"\n",
    "        self.test= pd.read_sql(query_test, cnx)\n",
    "        \n",
    "        query_questions = \"SELECT * FROM questions\"\n",
    "        self.questions= pd.read_sql(query_questions, cnx)\n",
    "        \n",
    "        query_options = \"SELECT * FROM mcq_options\"\n",
    "        self.options= pd.read_sql(query_options, cnx)\n",
    "        \n",
    "        query_responses = \"SELECT * FROM responses\"\n",
    "        self.responses= pd.read_sql(query_responses, cnx)\n",
    "        \n",
    "        query_olap_test = \"SELECT * FROM olap_test\"\n",
    "        self.olap_test= pd.read_sql(query_olap_test, cnx)\n",
    "        \n",
    "        query_olap_question = \"SELECT * FROM olap_question\"\n",
    "        self.olap_question= pd.read_sql(query_olap_question, cnx)\n",
    "        \n",
    "        cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLAP_Test:\n",
    "    df:dataframes\n",
    "    results={'id': 0, 'testId':0, 'totalAppeared':0, 'maxMarks':0, 'highestMarks':0, 'lowestMarks':0,\n",
    "             'avgMarks':0, 'noOfPassed':0, 'noOfFailed':0, 'lastUpdated': ''}\n",
    "    testId=0\n",
    "    \n",
    "    def __init__(self, df: dataframes, testId: int) -> None:\n",
    "        self.df=df\n",
    "        self.testId=testId\n",
    "        self.results['testId']=testId\n",
    "        \n",
    "        \n",
    "    def calculate(self):\n",
    "        \n",
    "        responses=self.df.responses.query('testId==@self.testId')\n",
    "        test=self.df.test.query('id==@self.testId')\n",
    "        \n",
    "        def setTotalAppeared():\n",
    "            self.results['totalAppeared']=len(responses['userId'].unique())\n",
    "        \n",
    "        def setMaxMarks():\n",
    "            mm=test['maxMarks'].loc[0]\n",
    "            self.results['maxMarks']=mm\n",
    "        \n",
    "        def setHighestMarks():\n",
    "            max_score = responses.groupby('userId')['obtainedMarks'].sum().max()\n",
    "            self.results['highestMarks']=max_score\n",
    "            \n",
    "        def setLowestMarks():\n",
    "            min_score = responses.groupby('userId')['obtainedMarks'].sum().min()\n",
    "            self.results['lowestMarks']=min_score\n",
    "        \n",
    "        def setAvgMarks():\n",
    "            average_marks = responses.groupby('userId')['obtainedMarks'].sum().mean()\n",
    "            self.results['avgMarks']=average_marks\n",
    "        \n",
    "        def setNoOfPassedandFailed():\n",
    "            passMarks=test.passMarks.loc[0]\n",
    "            passed=(responses.groupby('userId')['obtainedMarks'].sum() >= passMarks).sum()\n",
    "            self.results['noOfPassed']=passed\n",
    "            self.results['noOfFailed']=self.results['totalAppeared']-passed\n",
    "        setTotalAppeared()\n",
    "        setMaxMarks()\n",
    "        setHighestMarks()\n",
    "        setLowestMarks()\n",
    "        setAvgMarks()\n",
    "        setNoOfPassedandFailed()\n",
    "        return self.results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzes one question by its ID\n",
    "class OLAP_questions:\n",
    "    df:dataframes\n",
    "    result={'id': 0, 'questionId':0, 'maxMarks':0, 'highestMarks':0, 'lowestMarks':0,\n",
    "             'avgMarks':0, 'topic': ''}\n",
    "    testId:int\n",
    "    \n",
    "    #maps dataframes created and locks the testId\n",
    "    def __init__(self, df:dataframes, testId: int):\n",
    "        self.df=df\n",
    "        self.testId=testId\n",
    "        \n",
    "    #calculates analysis for a particular question by questionId\n",
    "    def calculate(self,questionId:int):\n",
    "        responses=self.df.responses.query('questionId==@questionId')\n",
    "        question=self.df.questions.query('id==@questionId')\n",
    "        self.result['questionId']=questionId\n",
    "        self.result['topic']=question['topic'].iloc[0]\n",
    "        self.result['maxMarks']=question['maxMarks'].iloc[0]\n",
    "        self.result['highestMarks']=responses['obtainedMarks'].max()\n",
    "        self.result['lowestMarks']=responses['obtainedMarks'].min()\n",
    "        self.result['avgMarks']=responses['obtainedMarks'].mean()\n",
    "\n",
    "        return self.result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#analyzes test scores wrt topics\n",
    "class studentAnalysis:\n",
    "    testId:int\n",
    "    df:dataframes\n",
    "    def __init__(self,df:dataframes) -> None:\n",
    "        self.df=df\n",
    "        \n",
    "    def getTestData(self, testId:int, studentId: int):\n",
    "        olapTest=OLAP_Test(df=self.df,testId=testId)\n",
    "        results=olapTest.calculate()\n",
    "        responses=self.df.responses.query('testId==@testId & userId==@studentId')\n",
    "        results['studentId']=studentId\n",
    "        results['totalMarksObtained']=responses['obtainedMarks'].sum()\n",
    "        return results\n",
    "    \n",
    "    def getQuestionData(self, testId:int, studentId: int, questionId: int):\n",
    "        olapq=OLAP_questions(df=self.df,testId=testId)\n",
    "        result=olapq.calculate(questionId=questionId)\n",
    "        response=self.df.responses.query('testId==@testId & userId==@studentId & questionId==@questionId')\n",
    "        result['obtainedMarks']=response['obtainedMarks'].iloc[0]\n",
    "        return result\n",
    "    \n",
    "    def getStudents(self,testId:int):\n",
    "        responses=self.df.responses.query('testId==@testId')\n",
    "        userIdList=responses.userId.unique()\n",
    "        results=[]\n",
    "        for id in userIdList:\n",
    "            data={}\n",
    "            user=self.df.user.query('id==@id').iloc[0]\n",
    "            data['userId']=id\n",
    "            data['firstName']=user['firstName']\n",
    "            data['lastName']=user['lastName']\n",
    "            data['obtainedMarks']=self.getTestData(testId=testId,studentId=id)['totalMarksObtained']\n",
    "            results.append(data)\n",
    "        return results\n",
    "    \n",
    "    def getTopicAnalysis(self, testId:int, userId:int):\n",
    "        questions = self.df.questions.query('testId==@testId')\n",
    "        responses = self.df.responses.query('testId==@testId')\n",
    "        topics=questions['topic'].unique()\n",
    "        \n",
    "        def data(topic:str,averageMarks:float,yourMarks:int,highestMarks:int,lowestMarks:int):\n",
    "            body={}\n",
    "            body['topic']=topic\n",
    "            body['averageMarks']=averageMarks\n",
    "            body['yourMarks']=yourMarks\n",
    "            body['highestMarks']=highestMarks\n",
    "            body['lowestMarks']=lowestMarks\n",
    "            return body\n",
    "\n",
    "        merged_df = questions.merge(responses, left_on='id', right_on='questionId')\n",
    "        results=[]\n",
    "        \n",
    "        merged_df = pd.merge(questions, responses, left_on='id', right_on='questionId')\n",
    "\n",
    "        user_marks_sum = merged_df.groupby(['topic', 'userId'])['obtainedMarks'].agg('sum').reset_index()\n",
    "        most_marks_by_user = user_marks_sum.groupby('topic').agg('max').reset_index()\n",
    "        avg_marks_by_topic = merged_df.groupby('topic')['obtainedMarks'].agg('mean').reset_index()\n",
    "        least_marks_by_user = user_marks_sum.groupby('topic').agg('min').reset_index()\n",
    "        \n",
    "        for topic in topics:\n",
    "            yourMarks=user_marks_sum.query('topic==@topic & userId==@userId')['obtainedMarks'].iloc[0]\n",
    "            highestMarks=most_marks_by_user.query('topic==@topic')['obtainedMarks'].iloc[0]\n",
    "            averageMarks=avg_marks_by_topic.query('topic==@topic')['obtainedMarks'].iloc[0]\n",
    "            lowestMarks=least_marks_by_user.query('topic==@topic')['obtainedMarks'].iloc[0]\n",
    "            results.append(data(topic=topic,averageMarks=averageMarks,yourMarks=yourMarks,highestMarks=highestMarks,lowestMarks=lowestMarks))\n",
    "        return results\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'testId': 1, 'totalAppeared': 4, 'maxMarks': 15, 'highestMarks': 15, 'lowestMarks': 0, 'avgMarks': 7.5, 'noOfPassed': 2, 'noOfFailed': 2, 'lastUpdated': '', 'studentId': 2, 'totalMarksObtained': 15}\n",
      "{'id': 0, 'questionId': 1, 'maxMarks': 5, 'highestMarks': 5, 'lowestMarks': 0, 'avgMarks': 2.5, 'topic': 'Cities', 'obtainedMarks': 0}\n",
      "[{'userId': 2, 'firstName': 'Shahrukh', 'lastName': 'Khan', 'obtainedMarks': 15}, {'userId': 3, 'firstName': 'Salman', 'lastName': 'Khan', 'obtainedMarks': 0}, {'userId': 4, 'firstName': 'Aamir', 'lastName': 'Khan', 'obtainedMarks': 5}, {'userId': 5, 'firstName': 'Hrithik', 'lastName': 'Roshan', 'obtainedMarks': 10}]\n"
     ]
    }
   ],
   "source": [
    "df=dataframes()\n",
    "sa=studentAnalysis(df)\n",
    "print(sa.getTestData(testId=1, studentId= 2))\n",
    "print(sa.getQuestionData(testId=1,studentId=3,questionId=1))\n",
    "print(sa.getStudents(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cities', 'Government', 'Animals'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions=df.questions.query('testId==1')\n",
    "topics=questions['topic'].unique()\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = df.questions\n",
    "responses = df.responses\n",
    "\n",
    "merged_df = pd.merge(questions, responses, left_on='id', right_on='questionId')\n",
    "\n",
    "user_marks_sum = merged_df.groupby(['topic', 'userId'])['obtainedMarks'].agg('sum').reset_index()\n",
    "most_marks_by_user = user_marks_sum.groupby('topic').agg('max').reset_index()\n",
    "avg_marks_by_topic = merged_df.groupby('topic')['obtainedMarks'].agg('mean').reset_index()\n",
    "least_marks_by_user = user_marks_sum.groupby('topic').agg('min').reset_index()\n",
    "\n",
    "\n",
    "# display(merged_df)\n",
    "# display(user_marks_sum)\n",
    "# display(most_marks_by_user)\n",
    "# display(avg_marks_by_topic)\n",
    "# display(least_marks_by_user)\n",
    "\n",
    "most_marks_by_user.query('topic==\"Animals\"')['obtainedMarks'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic': 'Cities',\n",
       "  'averageMarks': 2.5,\n",
       "  'yourMarks': 0,\n",
       "  'highestMarks': 5,\n",
       "  'lowestMarks': 0},\n",
       " {'topic': 'Government',\n",
       "  'averageMarks': 2.5,\n",
       "  'yourMarks': 5,\n",
       "  'highestMarks': 5,\n",
       "  'lowestMarks': 0},\n",
       " {'topic': 'Animals',\n",
       "  'averageMarks': 2.5,\n",
       "  'yourMarks': 0,\n",
       "  'highestMarks': 5,\n",
       "  'lowestMarks': 0}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=sa.getTopicAnalysis(testId=1,userId=4)\n",
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
